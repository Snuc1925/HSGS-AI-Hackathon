{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport os.path as osp\nimport time\nimport datetime\nimport random\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport torch.nn as nn\nfrom torch.autograd import Function\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport tensorflow as tf\nimport torch\nimport pandas as pd\nimport torch.utils.data as data\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\nimport logging\nfrom torchvision import datasets,transforms, models\nfrom tqdm.notebook import tqdm\nimport glob\nimport matplotlib.image as image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Dense,Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-25T14:09:59.948064Z","iopub.execute_input":"2022-07-25T14:09:59.948471Z","iopub.status.idle":"2022-07-25T14:10:08.119633Z","shell.execute_reply.started":"2022-07-25T14:09:59.948430Z","shell.execute_reply":"2022-07-25T14:10:08.118404Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#TRAIN_DATA\ntrain_data = np.array([])\nfor r, dirnames, fn in os.walk('../input/hsgs-hackathon2022/train_data/Train'):\n    for dirname in sorted(dirnames):\n        print(dirname)\n        cur_path = '../input/hsgs-hackathon2022/train_data/Train' + '/' + dirname\n        for filename in sorted(os.listdir(cur_path)):\n            train_data = np.append(train_data, os.path.join(cur_path, filename))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:10:20.105267Z","iopub.execute_input":"2022-07-25T14:10:20.105959Z","iopub.status.idle":"2022-07-25T14:11:36.072894Z","shell.execute_reply.started":"2022-07-25T14:10:20.105924Z","shell.execute_reply":"2022-07-25T14:11:36.071622Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n# #show a Image\n# img = Image.open(train_data[21660])\n# transform = transforms.Resize((224, 224))\n# resized_image = transform(img)\n\n# resized_image\n# # Convert a image path from list to matrix\n# # im = image.imread(train_data[20000])\n# # im.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-23T11:54:40.635360Z","iopub.execute_input":"2022-07-23T11:54:40.635816Z","iopub.status.idle":"2022-07-23T11:54:40.641306Z","shell.execute_reply.started":"2022-07-23T11:54:40.635771Z","shell.execute_reply":"2022-07-23T11:54:40.640005Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# TRAIN_LABEL\ntrain_label = np.array([])\ncurDir = '../input/hsgs-hackathon2022/train_data/Train_labels'\nfor file in sorted(os.listdir(curDir)):\n    datas = pd.read_csv(f'{os.path.join(curDir, file)}').values\n    label_data = datas[:, 1]\n    train_label = np.concatenate((train_label, label_data), axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:13:07.273359Z","iopub.execute_input":"2022-07-25T14:13:07.273813Z","iopub.status.idle":"2022-07-25T14:13:07.385157Z","shell.execute_reply.started":"2022-07-25T14:13:07.273771Z","shell.execute_reply":"2022-07-25T14:13:07.384176Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"IM_SIZE = 224\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:14:11.168273Z","iopub.execute_input":"2022-07-25T14:14:11.169397Z","iopub.status.idle":"2022-07-25T14:14:11.174966Z","shell.execute_reply.started":"2022-07-25T14:14:11.169345Z","shell.execute_reply":"2022-07-25T14:14:11.173801Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"Transform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.Resize((IM_SIZE, IM_SIZE)),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:12:57.486523Z","iopub.execute_input":"2022-07-25T15:12:57.486990Z","iopub.status.idle":"2022-07-25T15:12:57.494227Z","shell.execute_reply.started":"2022-07-25T15:12:57.486953Z","shell.execute_reply":"2022-07-25T15:12:57.493254Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class GetData(Dataset):\n    def __init__(self, trainData, trainLabel, transform = None, isTrain = True):\n        self.trainData = trainData\n        self.trainLabel = trainLabel\n        self.transform = transform\n        self.isTrain = isTrain\n    \n    def __len__(self):\n        return len(self.trainData)\n    \n    def __getitem__(self, idx):\n        img_path = self.trainData[idx]\n        img = Image.open(img_path)\n        \n        if self.transform:\n            img_transformed = self.transform(img)\n        \n        if self.isTrain:\n            label = self.trainLabel[idx]\n            return img_transformed, label\n        else:\n            return img_transformed","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:13:00.367056Z","iopub.execute_input":"2022-07-25T15:13:00.368217Z","iopub.status.idle":"2022-07-25T15:13:00.377450Z","shell.execute_reply.started":"2022-07-25T15:13:00.368159Z","shell.execute_reply":"2022-07-25T15:13:00.376011Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"sum(train_label)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T10:19:05.597846Z","iopub.execute_input":"2022-07-25T10:19:05.598503Z","iopub.status.idle":"2022-07-25T10:19:05.604547Z","shell.execute_reply.started":"2022-07-25T10:19:05.598464Z","shell.execute_reply":"2022-07-25T10:19:05.603832Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"train_XX = []\nval_XX = []\ntrain_YY = []\nval_YY = []\n\ncnt_x = 2000\ncnt_y = 2500\nidx = 0\n\nused = []\nfor _ in range(len(train_data)):\n    used.append(False)\n\nwhile True:\n    if cnt_x == 0 and cnt_y == 0:\n        break\n    \n    if cnt_x != 0 and train_label[idx] == 1:\n        train_XX.append(train_data[idx])\n        train_YY.append(1)\n        cnt_x -= 1\n        used[idx] = True\n    if cnt_y != 0 and train_label[idx] == 0:\n        train_XX.append(train_data[idx])\n        train_YY.append(0)\n        cnt_y -= 1\n        used[idx] = True\n    idx += 1\n\ncnt_x = 1000\ncnt_y = 1000\nidx = 0\n\nwhile True:\n    if cnt_x == 0 and cnt_y == 0:\n        break\n    if used[idx]:\n        idx += 1\n        continue\n    if cnt_x != 0 and train_label[idx] == 1:\n        val_XX.append(train_data[idx])\n        val_YY.append(1)\n        cnt_x -= 1\n    if cnt_y != 0 and train_label[idx] == 0:\n        val_XX.append(train_data[idx])\n        val_YY.append(0)\n        cnt_y -= 1\n    idx += 1","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:15:08.241094Z","iopub.execute_input":"2022-07-25T14:15:08.241513Z","iopub.status.idle":"2022-07-25T14:15:08.273880Z","shell.execute_reply.started":"2022-07-25T14:15:08.241481Z","shell.execute_reply":"2022-07-25T14:15:08.272683Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(GetData(train_XX, train_YY, Transform), batch_size = BATCH_SIZE)\nval_dataloader = DataLoader(GetData(val_XX, val_YY, Transform), batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:15:09.067116Z","iopub.execute_input":"2022-07-25T14:15:09.067512Z","iopub.status.idle":"2022-07-25T14:15:09.074354Z","shell.execute_reply.started":"2022-07-25T14:15:09.067481Z","shell.execute_reply":"2022-07-25T14:15:09.073346Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:15:10.885079Z","iopub.execute_input":"2022-07-25T14:15:10.885469Z","iopub.status.idle":"2022-07-25T14:15:10.892775Z","shell.execute_reply.started":"2022-07-25T14:15:10.885439Z","shell.execute_reply":"2022-07-25T14:15:10.891453Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_X, val_X, train_Y, val_Y = train_test_split(train_data[:6000], train_label[:6000], test_size = 0.2, random_state = 42)\ntrain_dataloader = DataLoader(GetData(train_X, train_Y, Transform), batch_size = BATCH_SIZE, shuffle = True)\nval_dataloader = DataLoader(GetData(val_X, val_Y, Transform), batch_size = BATCH_SIZE, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:30:12.385970Z","iopub.execute_input":"2022-07-25T15:30:12.387050Z","iopub.status.idle":"2022-07-25T15:30:12.396228Z","shell.execute_reply.started":"2022-07-25T15:30:12.387002Z","shell.execute_reply":"2022-07-25T15:30:12.394959Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:15:18.609801Z","iopub.execute_input":"2022-07-25T14:15:18.610233Z","iopub.status.idle":"2022-07-25T14:15:18.615632Z","shell.execute_reply.started":"2022-07-25T14:15:18.610197Z","shell.execute_reply":"2022-07-25T14:15:18.614727Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        # 3x224x224 => 32x222x222\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n        # 32x222x222 => 32x111x111\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        # 32x111x111 => 64x111x111\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same')\n        # 64x111x111 => 64x55x55\n        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n        self.linear1 = nn.Linear(64*55*55, 32)\n        self.linear2 = nn.Linear(32, 1)\n        self.sigmoid = nn.Sigmoid()\n  \n    def forward(self, x):\n        x = self.conv1(x)\n#         print(x.size())\n        x = self.maxpool1(x)\n#         print(x.size())\n        x = self.conv2(x)\n#         print(x.size())\n        x = self.avgpool(x)\n#         print(x.size())\n        x = torch.flatten(x, 1)\n#         print(x.size())\n        x = self.linear1(x)\n#         print(x.size())\n        x = self.linear2(x)\n#         print(x.size())\n        x = self.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-07-24T00:58:47.540911Z","iopub.execute_input":"2022-07-24T00:58:47.541463Z","iopub.status.idle":"2022-07-24T00:58:47.553326Z","shell.execute_reply.started":"2022-07-24T00:58:47.541433Z","shell.execute_reply":"2022-07-24T00:58:47.552295Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Model 1","metadata":{}},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_fts, out_fts, k, s, p, bias=False):\n        super(ConvBlock, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels=in_fts, out_channels=out_fts, kernel_size=k, stride=s, padding=p, bias=bias),\n            nn.BatchNorm2d(out_fts),\n            nn.ReLU(inplace=True)\n        )\n        \n    def forward(self, inp_img):\n        return self.conv(inp_img)\n\nclass MyModel(nn.Module):\n    def __init__(self, in_fts=3):\n        super(MyModel, self).__init__()\n        self.conv1 = ConvBlock(in_fts,64,7,2,3)\n        self.conv2 = ConvBlock(64,128,3,1,1)\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv3 = ConvBlock(128,256,3,1,1)\n        self.conv4 = ConvBlock(256,512,3,1,1)\n        self.conv5 = ConvBlock(512,512,3,1,1)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n        self.fc = nn.Sequential(\n            nn.Linear(512,300),\n            nn.Dropout(0.5),\n            nn.Linear(300,300),\n            nn.Dropout(0.5),\n            nn.Linear(300,1),\n            nn.Sigmoid()\n        )\n        \n\n    def forward(self, input_img):\n        N = input_img.shape[0]\n        x = self.conv1(input_img)\n        x = self.maxpool(x)\n        x = self.conv2(x)\n        x = self.maxpool(x)\n        x = self.conv3(x)\n        x = self.maxpool(x)\n        x = self.conv4(x)\n        x = self.maxpool(x)\n        x = self.conv5(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x,1)\n        x = self.fc(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-07-24T00:58:48.189519Z","iopub.execute_input":"2022-07-24T00:58:48.189941Z","iopub.status.idle":"2022-07-24T00:58:48.219447Z","shell.execute_reply.started":"2022-07-24T00:58:48.189910Z","shell.execute_reply":"2022-07-24T00:58:48.213630Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def Training(train_loader, val_loader):\n    EPOCHS = 3\n    for epoch in range(3):\n        #Train\n        total_loss_train = 0\n        total_acc_train = 0\n        \n        loop = tqdm(train_loader)\n        loop.set_description(f\"{epoch + 1} / {EPOCHS}\")\n        \n        count = 1\n        \n        for x, y in loop:\n            x = x.to(device)\n            y = y.to(device)\n            \n            output = model(x.float())\n            batch_loss = criterion(torch.squeeze(output), y.float())\n            total_loss_train += batch_loss.item()\n            \n            pred = []\n            \n            for i in output:\n                if i.item() >= 0.5:\n                    pred.append(1)\n                else:\n                    pred.append(0)\n\n            accuracy = torch.mean((torch.tensor(pred).to(device) == y).float())\n            total_acc_train += accuracy.item()\n\n            optimizer.zero_grad()\n            batch_loss.backward()\n            optimizer.step()\n\n            loop.set_postfix({'Train Loss': total_loss_train / count,'Train Accuracy': total_acc_train / count})\n            count += 1\n        \n        #Validation\n        \n        iteration = 1\n        loop = tqdm(val_loader)\n        total_val_loss, total_val_accuracy = 0,0\n        model.eval()\n        with torch.no_grad():\n            for img,label in loop:\n                img = img.to(device)\n                label = label.to(device)\n                output = model(img)\n\n                L = criterion(output, label.float().unsqueeze(1))\n                total_val_loss += L.item()\n\n                pred = []\n                for i in output:\n                    if i.item() >= 0.5:\n                        pred.append(1)\n                    else:\n                        pred.append(0)\n\n                accuracy = torch.mean((torch.tensor(pred).to(device) == label).float())\n                total_val_accuracy += accuracy.item()\n\n                loop.set_postfix({'Val Loss':total_val_loss/iteration,'Val Accuracy':total_val_accuracy/iteration})\n                iteration += 1\n        model.train()\n        scheduler.step(total_val_loss/iteration)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T01:06:27.375562Z","iopub.execute_input":"2022-07-24T01:06:27.376011Z","iopub.status.idle":"2022-07-24T01:06:27.398740Z","shell.execute_reply.started":"2022-07-24T01:06:27.375979Z","shell.execute_reply":"2022-07-24T01:06:27.397537Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = MyModel()\nLR = 1e-1\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True)\n\ncriterion = nn.BCELoss()\n# optimizer = torch.optim.Adam(model.parameters())\noptimizer = torch.optim.SGD(model.parameters(), lr = LR)\n\nmodel = model.to(device)\ncriterion = criterion.to(device)\n\n\n\nTraining(train_dataloader, val_dataloader)\n\n# kf = KFold(n_splits = 3, random_state = 42, shuffle = True)\n\n# for train_index, val_index in kf.split(train_data[:4500]):\n#     train_X = []\n#     train_Y = []\n#     for idx in train_index:\n#         train_X.append(train_data[idx])\n#         train_Y.append(train_label[idx])\n    \n#     val_X = []\n#     val_Y = []\n#     for idx in val_index:\n#         val_X.append(train_data[idx])\n#         val_Y.append(train_label[idx])\n    \n#     train_dataloader = DataLoader(GetData(train_X, train_Y, Transform), batch_size = BATCH_SIZE)\n#     val_dataloader = DataLoader(GetData(val_X, val_Y, Transform), batch_size = BATCH_SIZE)\n#     Training(train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T01:07:16.082571Z","iopub.execute_input":"2022-07-24T01:07:16.083870Z","iopub.status.idle":"2022-07-24T01:07:55.271057Z","shell.execute_reply.started":"2022-07-24T01:07:16.083799Z","shell.execute_reply":"2022-07-24T01:07:55.269506Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true,"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if param.requires_grad:\n        print (name, param.data)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-07-23T18:15:24.460196Z","iopub.execute_input":"2022-07-23T18:15:24.461002Z","iopub.status.idle":"2022-07-23T18:15:24.482694Z","shell.execute_reply.started":"2022-07-23T18:15:24.460955Z","shell.execute_reply":"2022-07-23T18:15:24.481762Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true,"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"save_path = \"MyModel.pt\"\ntorch.save(model, save_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T02:54:34.836445Z","iopub.execute_input":"2022-07-24T02:54:34.836828Z","iopub.status.idle":"2022-07-24T02:54:34.878413Z","shell.execute_reply.started":"2022-07-24T02:54:34.836801Z","shell.execute_reply":"2022-07-24T02:54:34.876588Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Model 2 (VGG)","metadata":{}},{"cell_type":"code","source":"class MyVGG(nn.Module):\n    def __init__(self):\n        super(MyVGG, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = 'same')\n        self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 'same')\n        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 'same')\n        self.conv4 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 'same')\n        self.conv5 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 'same')\n        self.conv6 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 'same')\n        self.conv7 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 'same')\n        self.conv8 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 'same')\n        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        self.relu = nn.ReLU(inplace = True)\n        self.linear1 = nn.Linear(7*7*512, 4096)\n        self.linear2 = nn.Linear(4096, 4096)\n        self.linear3 = nn.Linear(4096, 1)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.conv2(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.maxpool(x)\n#         print(x.shape)\n        x = self.conv3(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.conv4(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.maxpool(x)\n#         print(x.shape)\n        x = self.conv5(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.conv6(x)\n        x = self.relu(x)\n#         print(x.shape)\n\n        x = self.conv6(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.maxpool(x)\n#         print(x.shape)\n        x = self.conv7(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.conv8(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.conv8(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.maxpool(x)\n#         print(x.shape)\n        x = self.conv8(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.conv8(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.conv8(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.maxpool(x)\n#         print(x.shape)\n        x = torch.flatten(x, 1)\n#         print(x.shape)\n        x = self.linear1(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.linear2(x)\n        x = self.relu(x)\n#         print(x.shape)\n        x = self.linear3(x)\n#         print(x.shape)\n        x = self.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-07-24T03:27:37.118301Z","iopub.execute_input":"2022-07-24T03:27:37.118721Z","iopub.status.idle":"2022-07-24T03:27:37.138136Z","shell.execute_reply.started":"2022-07-24T03:27:37.118687Z","shell.execute_reply":"2022-07-24T03:27:37.136712Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def Training_VGG(train_loader, val_loader, model_def, loss_fn):\n    EPOCHS = 3\n    for epoch in range(3):\n        #Train\n        total_loss_train = 0\n        total_acc_train = 0\n        \n        loop = tqdm(train_loader)\n        loop.set_description(f\"{epoch + 1} / {EPOCHS}\")\n        \n        count = 1\n        \n        for x, y in loop:\n            x = x.to(device)\n            y = y.to(device)\n            \n            output = model_def(x.float())\n            batch_loss = loss_fn(torch.squeeze(output), y.float())\n            total_loss_train += batch_loss.item()\n            \n            pred = []\n            \n            for a in output:\n                if a.item() >= 0.5:\n                    pred.append(1)\n                else:\n                    pred.append(0)\n\n            accuracy = torch.mean((torch.tensor(pred).to(device) == y).float())\n            total_acc_train += accuracy.item()\n\n            optimizer.zero_grad()\n            batch_loss.backward()\n            optimizer.step()\n\n            loop.set_postfix({'Train Loss': total_loss_train / count,'Train Accuracy': total_acc_train / count})\n            count += 1\n        \n        #Validation\n        \n        iteration = 1\n        loop = tqdm(val_loader)\n        total_val_loss, total_val_accuracy = 0,0\n        model_def.eval()\n        with torch.no_grad():\n            for img,label in loop:\n                img = img.to(device)\n                label = label.to(device)\n                output = model_def(img)\n\n                L = loss_fn(output, label.float().unsqueeze(1))\n                total_val_loss += L.item()\n\n                pred = []\n                for a in output:\n                    if a.item() >= 0.5:\n                        pred.append(1)\n                    else:\n                        pred.append(0)\n\n                accuracy = torch.mean((torch.tensor(pred).to(device) == label).float())\n                total_val_accuracy += accuracy.item()\n\n                loop.set_postfix({'Val Loss':total_val_loss/iteration,'Val Accuracy':total_val_accuracy/iteration})\n                iteration += 1\n        model_def.train()\n        scheduler.step(total_val_loss/iteration)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T03:27:38.236650Z","iopub.execute_input":"2022-07-24T03:27:38.237537Z","iopub.status.idle":"2022-07-24T03:27:38.253017Z","shell.execute_reply.started":"2022-07-24T03:27:38.237489Z","shell.execute_reply":"2022-07-24T03:27:38.251915Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_vgg = MyVGG()\nLR = 1e-1\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\noptimizer = torch.optim.SGD(model_vgg.parameters(), lr = LR)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True)\n\ncriterion = nn.BCELoss()\n# optimizer = torch.optim.Adam(model.parameters())\n\nmodel_vgg = model_vgg.to(device)\ncriterion = criterion.to(device)\nTraining_VGG(train_dataloader, val_dataloader, model_vgg, criterion)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T13:47:50.573780Z","iopub.execute_input":"2022-07-24T13:47:50.574172Z","iopub.status.idle":"2022-07-24T13:47:50.603906Z","shell.execute_reply.started":"2022-07-24T13:47:50.574139Z","shell.execute_reply":"2022-07-24T13:47:50.602143Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model ResNet\n","metadata":{}},{"cell_type":"code","source":"import torchvision\nfrom torchinfo import summary","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:15:38.891594Z","iopub.execute_input":"2022-07-25T14:15:38.891964Z","iopub.status.idle":"2022-07-25T14:15:38.905640Z","shell.execute_reply.started":"2022-07-25T14:15:38.891930Z","shell.execute_reply":"2022-07-25T14:15:38.904672Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"!pip install torchinfo","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:15:25.864623Z","iopub.execute_input":"2022-07-25T14:15:25.865007Z","iopub.status.idle":"2022-07-25T14:15:38.888824Z","shell.execute_reply.started":"2022-07-25T14:15:25.864978Z","shell.execute_reply":"2022-07-25T14:15:38.887311Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"pre_trained = torchvision.models.resnet18(pretrained=True)\npre_trained = pre_trained.to(device)\n# for param in pre_trained.parameters():\n#     param.requires_grad = False\npre_trained","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:22:25.078207Z","iopub.execute_input":"2022-07-25T15:22:25.078636Z","iopub.status.idle":"2022-07-25T15:22:25.558964Z","shell.execute_reply.started":"2022-07-25T15:22:25.078599Z","shell.execute_reply":"2022-07-25T15:22:25.557920Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for name, param in pre_trained.fc.named_parameters():\n    print(param.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T08:18:23.066860Z","iopub.execute_input":"2022-07-25T08:18:23.067272Z","iopub.status.idle":"2022-07-25T08:18:23.074095Z","shell.execute_reply.started":"2022-07-25T08:18:23.067238Z","shell.execute_reply":"2022-07-25T08:18:23.072790Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"net = nn.Sequential(\n    pre_trained,\n    nn.Dropout(0.2),\n    nn.Linear(in_features = 1000, out_features = 256),\n    nn.Dropout(0.2),\n    nn.Linear(in_features = 256,  out_features = 1),\n    nn.Sigmoid()\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:30:18.947817Z","iopub.execute_input":"2022-07-25T15:30:18.948232Z","iopub.status.idle":"2022-07-25T15:30:18.956949Z","shell.execute_reply.started":"2022-07-25T15:30:18.948198Z","shell.execute_reply":"2022-07-25T15:30:18.955812Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"net","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:16:27.491615Z","iopub.execute_input":"2022-07-25T14:16:27.492008Z","iopub.status.idle":"2022-07-25T14:16:27.501120Z","shell.execute_reply.started":"2022-07-25T14:16:27.491979Z","shell.execute_reply":"2022-07-25T14:16:27.499850Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"for name, param in net[0].named_parameters():\n    print(param)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T08:17:48.783041Z","iopub.execute_input":"2022-07-25T08:17:48.784151Z","iopub.status.idle":"2022-07-25T08:17:48.936163Z","shell.execute_reply.started":"2022-07-25T08:17:48.784097Z","shell.execute_reply":"2022-07-25T08:17:48.935032Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"LR = 1e-2\ncriterion_res = nn.BCELoss()\noptimizer_res = torch.optim.SGD(net.parameters(), lr = LR, momentum = 0.9)\nscheduler_res = optim.lr_scheduler.ReduceLROnPlateau(optimizer_res, patience=1, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:30:23.867384Z","iopub.execute_input":"2022-07-25T15:30:23.867807Z","iopub.status.idle":"2022-07-25T15:30:23.874559Z","shell.execute_reply.started":"2022-07-25T15:30:23.867771Z","shell.execute_reply":"2022-07-25T15:30:23.873585Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"n_epochs = 5\ntotal_step = len(train_dataloader)\n\nval_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\n\nfor epoch in range(1, n_epochs + 1):\n    total_train_loss = 0.0\n    total_train_acc = 0.0\n    \n    count = 1\n    loop = tqdm(train_dataloader)\n    loop.set_description(f\"{epoch}/{n_epochs}\")\n    \n    for (x, y) in loop:\n        x = x.to(device)\n        y = y.to(device)\n        optimizer_res.zero_grad()\n        \n        output = net(x)\n        loss = criterion_res(output, y.float().unsqueeze(1))\n        loss.backward()\n        optimizer_res.step()\n        \n        total_train_loss += loss.item()\n        \n        pred = []\n        for i in output:\n            if i.item() >= 0.5:\n                pred.append(1)\n            else:\n                pred.append(0)\n        \n        acc = torch.mean((torch.tensor(pred).to(device) == y).float())\n        total_train_acc += acc.item()\n        \n        loop.set_postfix({'Train Loss:': total_train_loss / count, 'Train Accuracy:': total_train_acc / count})\n        count += 1\n    \n    train_acc.append(total_train_acc / count)\n    train_loss.append(total_train_loss / count)\n    \n    \n    #Validation\n    \n    count = 1\n    total_val_acc = 0\n    total_val_loss = 0\n    \n    loop = tqdm(val_dataloader)\n    \n    with torch.no_grad():\n        net.eval()\n        for x, y in loop:\n            x = x.to(device)\n            y = y.to(device)\n            output_t = net(x)\n            loss_t = criterion_res(output_t, y.float().unsqueeze(1))\n            total_val_loss += loss_t.item()\n            \n            pred = []\n            for i in output_t:\n                if i.item() >= 0.5:\n                    pred.append(1)\n                else:\n                    pred.append(0)\n            \n            acc = torch.mean((torch.tensor(pred).to(device) == y).float())\n            total_val_acc += acc.item()\n            \n            loop.set_postfix({'Val Loss:': total_val_loss / count, 'Val Accuracy:': total_val_acc / count})\n            count += 1\n            \n        val_acc.append(total_val_acc/count)\n        val_loss.append(total_val_loss/count)\n    net.train()\n    scheduler_res.step(total_val_loss/count)\n    \n    save_myModel = f\"MyModel{epoch}.pt\"\n    torch.save(net, save_myModel)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:30:30.036377Z","iopub.execute_input":"2022-07-25T15:30:30.036808Z","iopub.status.idle":"2022-07-25T16:30:47.978418Z","shell.execute_reply.started":"2022-07-25T15:30:30.036775Z","shell.execute_reply":"2022-07-25T16:30:47.977039Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"a = torch.Tensor([3,4,5])\nb = torch.Tensor([4,5,5])\ntorch.sum(a==b).item()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T01:25:32.109614Z","iopub.execute_input":"2022-07-25T01:25:32.110058Z","iopub.status.idle":"2022-07-25T01:25:32.119265Z","shell.execute_reply.started":"2022-07-25T01:25:32.110027Z","shell.execute_reply":"2022-07-25T01:25:32.118050Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"save_path = \"MyResNet3.pt\"\ntorch.save(net, save_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:54:08.976383Z","iopub.execute_input":"2022-07-25T14:54:08.977475Z","iopub.status.idle":"2022-07-25T14:54:09.080090Z","shell.execute_reply.started":"2022-07-25T14:54:08.977432Z","shell.execute_reply":"2022-07-25T14:54:09.078781Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"test_data = np.array([])\ntest_data_path = []\nfor r, dirnames, fn in os.walk('../input/hsgs-hackathon2022/Test_data/Test'):\n    for dirname in sorted(dirnames):\n        print(dirname)\n        cur_path = '../input/hsgs-hackathon2022/Test_data/Test' + '/' + dirname\n        for filename in sorted(os.listdir(cur_path)):\n            test_data = np.append(test_data, os.path.join(cur_path, filename))\n            test_data_path.append(dirname + '_' + filename[:-4])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:54:38.648033Z","iopub.execute_input":"2022-07-25T14:54:38.648489Z","iopub.status.idle":"2022-07-25T14:54:50.189957Z","shell.execute_reply.started":"2022-07-25T14:54:38.648452Z","shell.execute_reply":"2022-07-25T14:54:50.188661Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"test_dataset = GetData(test_data, _, Transform, False)\ntest_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:54:54.027113Z","iopub.execute_input":"2022-07-25T14:54:54.028048Z","iopub.status.idle":"2022-07-25T14:54:54.033960Z","shell.execute_reply.started":"2022-07-25T14:54:54.028000Z","shell.execute_reply":"2022-07-25T14:54:54.032556Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"for idx in range(1, 6):\n    test_model = torch.load(f'../working/MyModel{idx}.pt')\n    test_model = test_model.to(device)\n    test_model.eval()\n    loop = tqdm(test_dataloader)\n    test_pred = []\n    \n    with torch.no_grad():\n        for img in loop:\n            img = img.to(device)\n            output = temp_model(img)\n\n            for i in output:\n                if i.item() >= 0.5:\n                    test_pred.append(1)\n                else:\n                    test_pred.append(0)\n    submission = pd.DataFrame(data = zip(test_data_path, test_pred), columns = [\"Frame\", \"Label\"])\n    submission.to_csv(f\"sub{idx}.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T16:34:27.780276Z","iopub.execute_input":"2022-07-25T16:34:27.780763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_model = torch.load(\"../working/MyResNet3.pt\")\ntemp_model = temp_model.to(device)\ntemp_model.eval()\nloop = tqdm(test_dataloader)\ntest_pred = []\n\nwith torch.no_grad():\n    for img in loop:\n        img = img.to(device)\n        output = temp_model(img)\n        \n        for i in output:\n            if i.item() >= 0.5:\n                test_pred.append(1)\n            else:\n                test_pred.append(0)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T14:55:35.757027Z","iopub.execute_input":"2022-07-25T14:55:35.757465Z","iopub.status.idle":"2022-07-25T15:09:57.692191Z","shell.execute_reply.started":"2022-07-25T14:55:35.757422Z","shell.execute_reply":"2022-07-25T15:09:57.691140Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"len(test_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:10:01.910929Z","iopub.execute_input":"2022-07-25T15:10:01.911382Z","iopub.status.idle":"2022-07-25T15:10:01.919648Z","shell.execute_reply.started":"2022-07-25T15:10:01.911344Z","shell.execute_reply":"2022-07-25T15:10:01.918570Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(data = zip(test_data_path, test_pred), columns = [\"Frame\", \"Label\"])\nsubmission.to_csv(\"sub.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T15:10:04.946367Z","iopub.execute_input":"2022-07-25T15:10:04.946808Z","iopub.status.idle":"2022-07-25T15:10:04.999393Z","shell.execute_reply.started":"2022-07-25T15:10:04.946775Z","shell.execute_reply":"2022-07-25T15:10:04.998152Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-23T18:46:44.398819Z","iopub.execute_input":"2022-07-23T18:46:44.399930Z","iopub.status.idle":"2022-07-23T18:46:44.419201Z","shell.execute_reply.started":"2022-07-23T18:46:44.399889Z","shell.execute_reply":"2022-07-23T18:46:44.418282Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}